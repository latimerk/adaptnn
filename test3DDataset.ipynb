{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from adaptnn.model_fitting import NiruDataModel\n",
    "torch.set_default_device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building multi-layer convolutional model for 14 neurons and image size 50 x 50\n",
      "Adding Tucker convolutional layer of size (15, 15, 40) and 8 channels with factorization type spatial and rank 6.\n",
      "Adding nonlinearity: Softplus.\n",
      "Adding Tucker convolutional layer of size (11, 11, 12) and 8 channels with factorization type spatial and rank 6.\n",
      "Adding nonlinearity: Softplus.\n",
      "Adding final 3D batch normalization layer.\n",
      "Adding full-connected linear layer: [8, 26, 26] to 14.\n",
      "Adding output nonlinearity: Softplus.\n",
      "Model initialized.\n",
      "tensor([     0,    300,    600,  ..., 358800, 359100, 359400], device='cuda:0')\n",
      "torch.Size([1199])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/latimerk/gitRepos/adaptnn/src/adaptnn/retina_datasets.py:101: UserWarning: Segmentation of dataset leaves 51 time bins unseen.\n",
      "  warnings.warn(f\"Segmentation of dataset leaves {unused_bins} time bins unseen.\")\n"
     ]
    }
   ],
   "source": [
    "model = NiruDataModel()\n",
    "print(model.dataset.start_idx_X_train)\n",
    "print(model.dataset.start_idx_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/latimerk/gitRepos/adaptnn/src/adaptnn/retina_datasets.py:101: UserWarning: Segmentation of dataset leaves 251 time bins unseen.\n",
      "  warnings.warn(f\"Segmentation of dataset leaves {unused_bins} time bins unseen.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 50, 50, 550])\n",
      "torch.Size([2, 14, 500])\n"
     ]
    }
   ],
   "source": [
    "model.dataset.segment_length_bins = 500\n",
    "X1,Y1 = model.dataset[0]\n",
    "X1 = X1.unsqueeze(0)\n",
    "Y1 = Y1.unsqueeze(0)\n",
    "X2,Y2 = model.dataset[1]\n",
    "X2 = X2.unsqueeze(0)\n",
    "Y2 = Y2.unsqueeze(0)\n",
    "\n",
    "X = torch.cat([X1,X2],dim=0)\n",
    "Y = torch.cat([Y1,Y2],dim=0)\n",
    "# X = X1\n",
    "# Y = Y1\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "criterion = model.get_loss_function()\n",
    "optimizer = torch.optim.Adam(model.model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 95.50 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "55.9 ms ± 69.1 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "The slowest run took 309.77 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "211 ms ± 262 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "1.12 s ± 247 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "#Forward to get outputs\n",
    "%timeit  -r 5 -n 10  optimizer.zero_grad(); outputs=model.model(X)\n",
    "\n",
    "outputs=model.model(X)\n",
    "\n",
    "#calculate loss\n",
    "%timeit  -r 5 -n 10  optimizer.zero_grad(); outputs=model.model(X); loss=criterion(outputs, Y) \n",
    "\n",
    "loss=criterion(outputs, Y) \n",
    "\n",
    "#getting gradients wrt parameters\n",
    "%timeit  -r 5 -n 10  optimizer.zero_grad(); outputs=model.model(X); loss=criterion(outputs, Y); loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(epochs=200,print_every=1,print_every_batch=50,\n",
    "            optimizer_params = {\"lr\" : 1e-3},\n",
    "            scheduler_params = {\"start_factor\" : 1.0, \"end_factor\" : 0.1, \"total_iters\" : 100},\n",
    "            batch_params = {\"batch_size\":16, \"shuffle\":True},\n",
    "            # penalty_params = {\"en_lambda\" : 0.0001}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.model[4].weight_tucker.core.shape)\n",
    "for ii in model.model[4].weight_tucker.factors:\n",
    "    print(ii.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.model[4].weight_tucker.core.numel())\n",
    "tt = model.model[4].weight_tucker.core.numel()\n",
    "for ii in model.model[4].weight_tucker.factors:\n",
    "    print(ii.numel())\n",
    "    tt += ii.numel()\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
