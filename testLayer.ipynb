{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "\n",
    "from adaptnn.model_fitting import ArtificialModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building multi-layer convolutional model for 4 neurons and image size 15 x 15\n",
      "Adding 3D batch normalization layer.\n",
      "Adding Tucker convolutional layer of size (15, 15, 10) and 4 channels with factorization type spatial and rank 2.\n",
      "Adding nonlinearity: Softplus.\n",
      "Adding final 2D batch normalization layer.\n",
      "Adding full-connected linear layer: [4, 1, 1] to 4.\n",
      "Adding output nonlinearity: Softplus.\n",
      "Model initialized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([   0,  100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100,\n",
       "        1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300,\n",
       "        2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300, 3400, 3500,\n",
       "        3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700,\n",
       "        4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900,\n",
       "        6000, 6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100,\n",
       "        7200, 7300, 7400, 7500, 7600, 7700, 7800, 7900, 8000, 8100, 8200, 8300,\n",
       "        8400, 8500, 8600, 8700, 8800, 8900, 9000, 9100, 9200, 9300, 9400, 9500,\n",
       "        9600, 9700, 9800])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ArtificialModel(dataset_params = {\"filter_spatial\" : (15,15),\n",
    "                                         \"filter_time\" : 10,\n",
    "                                         \"num_cells\" : 4,\n",
    "                                         \"out_noise_std_train\" : None,\n",
    "                                         \"filter_rank\" : 2},\n",
    "                        net_params = {\"layer_time_lengths\" : (10,),\n",
    "                                     \"layer_rf_pixel_widths\" : (15,),\n",
    "                                     \"layer_channels\" : (4,),\n",
    "                                     \"layer_spatio_temporal_factorization_type\" : None,#('spatial',),\n",
    "                                     \"out_normalization\" : False,\n",
    "                                     \"layer_normalization\" : False})\n",
    "model.dataset.start_idx_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss 3.3182389736175537, step size 0.0001\n",
      "epoch 20, loss 3.2285097539424896, step size 0.0001\n",
      "epoch 30, loss 3.1402357518672943, step size 0.0001\n",
      "epoch 40, loss 3.0743955969810486, step size 0.0001\n",
      "epoch 50, loss 2.979604870080948, step size 0.0001\n",
      "epoch 60, loss 2.875470072031021, step size 0.0001\n",
      "epoch 70, loss 2.8333563208580017, step size 0.0001\n",
      "epoch 80, loss 2.759348303079605, step size 0.0001\n",
      "epoch 90, loss 2.69136643409729, step size 0.0001\n",
      "epoch 100, loss 2.6222414076328278, step size 0.0001\n",
      "epoch 110, loss 2.5605545341968536, step size 0.0001\n",
      "epoch 120, loss 2.51811483502388, step size 0.0001\n",
      "epoch 130, loss 2.5487888157367706, step size 0.0001\n",
      "epoch 140, loss 2.3875105679035187, step size 0.0001\n",
      "epoch 150, loss 2.384321689605713, step size 0.0001\n",
      "epoch 160, loss 2.3698324859142303, step size 0.0001\n",
      "epoch 170, loss 2.3442629873752594, step size 0.0001\n",
      "epoch 180, loss 2.3119997680187225, step size 0.0001\n",
      "epoch 190, loss 2.2516233921051025, step size 0.0001\n",
      "epoch 200, loss 2.2322855591773987, step size 0.0001\n",
      "epoch 210, loss 2.2009154856204987, step size 0.0001\n",
      "epoch 220, loss 2.199047327041626, step size 0.0001\n",
      "epoch 230, loss 2.1414490342140198, step size 0.0001\n",
      "epoch 240, loss 2.1537737250328064, step size 0.0001\n",
      "epoch 250, loss 2.143378347158432, step size 0.0001\n",
      "epoch 260, loss 2.1020225286483765, step size 0.0001\n",
      "epoch 270, loss 2.106372684240341, step size 0.0001\n",
      "epoch 280, loss 2.052852123975754, step size 0.0001\n",
      "epoch 290, loss 2.0461295545101166, step size 0.0001\n",
      "epoch 300, loss 2.029784172773361, step size 0.0001\n",
      "epoch 310, loss 1.9874813258647919, step size 0.0001\n",
      "epoch 320, loss 1.981621414422989, step size 0.0001\n",
      "epoch 330, loss 1.9955317974090576, step size 0.0001\n",
      "epoch 340, loss 1.992994248867035, step size 0.0001\n",
      "epoch 350, loss 1.9570651352405548, step size 0.0001\n",
      "epoch 360, loss 1.9524395763874054, step size 0.0001\n",
      "epoch 370, loss 1.9294891059398651, step size 0.0001\n",
      "epoch 380, loss 1.9201732575893402, step size 0.0001\n",
      "epoch 390, loss 1.9075663387775421, step size 0.0001\n",
      "epoch 400, loss 1.918852299451828, step size 0.0001\n",
      "epoch 410, loss 1.896640494465828, step size 0.0001\n",
      "epoch 420, loss 1.8651678264141083, step size 0.0001\n",
      "epoch 430, loss 1.882439523935318, step size 0.0001\n",
      "epoch 440, loss 1.8289956003427505, step size 0.0001\n",
      "epoch 450, loss 1.8350504338741302, step size 0.0001\n",
      "epoch 460, loss 1.8552036583423615, step size 0.0001\n",
      "epoch 470, loss 1.8289130181074142, step size 0.0001\n",
      "epoch 480, loss 1.8054022789001465, step size 0.0001\n",
      "epoch 490, loss 1.8254976570606232, step size 0.0001\n",
      "epoch 500, loss 1.8342183381319046, step size 0.0001\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs=500,print_every=10,penalty_params = {\"en_lambda\" : 0.0001}, scheduler_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_fit, Y_true = model.predict()\n",
    "Y_fit = Y_fit.numpy().squeeze()\n",
    "Y_true = Y_true.numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC = 4\n",
    "NR = int(np.ceil(model.dataset.num_cells)/NC)\n",
    "\n",
    "T = 100\n",
    "plt.figure(figsize=(NC*3,NR*2))\n",
    "for ii in range(model.dataset.num_cells):\n",
    "    plt.subplot(NR,NC,ii+1)\n",
    "    plt.plot(Y_true[ii,:T])\n",
    "    plt.plot(Y_fit[ ii,:T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Y2 = model.model(model.dataset.X_train.unsqueeze(0).unsqueeze(0)).numpy().squeeze()\n",
    "    Y1 = model.dataset.Y_train.numpy()[:,9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC = 4\n",
    "NR = int(np.ceil(model.dataset.num_cells)/NC)\n",
    "\n",
    "T = 1000\n",
    "plt.figure(figsize=(NC*3,NR*2))\n",
    "for ii in range(model.dataset.num_cells):\n",
    "    plt.subplot(NR,NC,ii+1)\n",
    "    plt.plot(Y1[ii,:T])\n",
    "    plt.plot(Y2[ ii,:T])\n",
    "    # plt.scatter(Y1[ii,:],Y1[ii,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
